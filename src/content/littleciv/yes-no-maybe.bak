
 
 Taking a slow, deliberative and structured approach, like many of the scientists working on different aspects of the climate challenge, allows us to grapple more accurately with the challenge at hand. Few of us though, have the time, resources or skill sets to delve deeply into the material; my recent review has covered a lot of ground but for every review of the literature and paper cited... one has to exercise judgment in determining a return on our investment in research time. This is one of the costs of hedging: it is more complex, so it requires more effort.
 
 
 
###### The Narrative Forcing and the "Yes, No, Maybe" brain
In [_Superforecasting_](https://amzn.to/2LF2q8h), Tetlock spends a whole chapter ("Probability for the Stone Age") on our default system for probability: "Gonna happen", "Not gonna happen" and "Maybe". To condense Tetlock's initial example, back in the Stone Age, we primarily needed our default system for probability to quickly determine whether that shimmer of movement from the tall grass over there is a lion or not. These map to three quick courses of action we can take: yes => run!, no => chill and maybe => stay alert and observe. Relaxing takes no energy. Running is high energy but gets you away from danger quickly. Staying alert, however, can be a tricky state. It does take more energy than relaxing but typically with a bit of time we can better appraise the situation, and get a firmer idea of whether bolting or chilling is in order. 

However, "Maybe" and staying in a constant state of vigilance gets old very quickly; it wears us down. Our climate challenge is an example of a complex situation that our default system for probability struggles to deal with, in large part because of its scale over time and space. It is a much more complex and systemic challenge that a lion, or the vast bulk of the predictions we make as we navigate traffic, other humans, and our daily lives. Tetlock contrasts this default system to our "system 2" thinking system for probability in the following chapter "Probability for the Information Age". In short, at the cost of time, effort and focused attention, we can overcome the short-comings of the "Yes, No, Maybe" part of the brain and get a better read on complex situations. Structured forecasting is an example of this. 

> Hearing about the possibility of climate chaos can pop people into this "stay alert" state; without a structured path out of that, our brain will force us out of a higher energy state, pushing our narrative about the climate into a rigid "yes" or "no".
 
 Even when we are effectively employing this structure though, our brains will frequently push us to simplify. I feel that regularly in my own forecasting, or even when looking at the numbers again. It is hard to discern this happening both in ourselves, and in others. 
 
 possible branch point here
 //  to "How could we tell if others are taking short-cuts"
 // return to the orientations and the impact of the yes, maybe, no thinking interjects
 // return to 'decision',
 // look at 'action'
 
 
 However, there are some clues we can observe in our own and others thinking that could indicate short-cuts are being made. 
 
  "narrative forcing" 